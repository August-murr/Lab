{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1z7telTELcmt"
      },
      "outputs": [],
      "source": [
        "# Install necessary packages\n",
        "!pip install bitsandbytes peft trl --quiet\n",
        "!pip install --upgrade datasets --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from datasets import Dataset, load_dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments, pipeline\n",
        "from peft import LoraConfig, prepare_model_for_kbit_training\n",
        "from trl import DPOTrainer\n",
        "import torch\n",
        "import wandb\n",
        "from kaggle_secrets import UserSecretsClient\n",
        "from huggingface_hub import login"
      ],
      "metadata": {
        "id": "ICMy3bexLdtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "data = load_dataset(\"August4293/Preference-Dataset\", split=\"train\")"
      ],
      "metadata": {
        "id": "kf9sqi6cLdrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing function\n",
        "def preprocess(data):\n",
        "    data['prompt'] = '<s>[INST]' + data['prompt'] + '[/INST]'\n",
        "    data['chosen'] += '</s>'\n",
        "    data['rejected'] += '</s>'\n",
        "    return data"
      ],
      "metadata": {
        "id": "fOgfHKNiLdo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.map(preprocess).train_test_split(test_size=0.1)\n",
        "train_dataset = data['train']\n",
        "eval_dataset = data['test']"
      ],
      "metadata": {
        "id": "rXg9_BrXLdmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve secrets\n",
        "user_secrets = UserSecretsClient()\n",
        "wandb_token = user_secrets.get_secret(\"wandb_august\")\n",
        "HF_token = user_secrets.get_secret(\"HF_august\")"
      ],
      "metadata": {
        "id": "0xzNQKVcLdjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Login to Hugging Face\n",
        "login(HF_token)"
      ],
      "metadata": {
        "id": "p-QDV0LgLdhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define run notes\n",
        "dataset_size = len(train_dataset)\n",
        "num_of_epochs = 1\n",
        "notes = f\"Initial DPO test run on sample dataset of {dataset_size} and {num_of_epochs} epochs\""
      ],
      "metadata": {
        "id": "t5-3Iig_Lde5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize WandB run\n",
        "wandb.login(key=wandb_token)\n",
        "run = wandb.init(\n",
        "    project='mistral self-alignment',\n",
        "    job_type=\"training\",\n",
        "    name=\"test run with DPO\",\n",
        "    notes=notes\n",
        ")"
      ],
      "metadata": {
        "id": "PJCy_gRBLdcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set base model and tokenizer\n",
        "base_model = \"/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = 'right'"
      ],
      "metadata": {
        "id": "nkyOPT8RLdZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure BitsAndBytes and Lora\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_use_double_quant=False,\n",
        ")"
      ],
      "metadata": {
        "id": "EAzLmiW_LdXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "peft_config = LoraConfig(\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1,\n",
        "    r=16,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
        ")"
      ],
      "metadata": {
        "id": "LlCYd6JMLdVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model,\n",
        "    quantization_config=bnb_config,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "model.config.use_cache = False\n",
        "model = prepare_model_for_kbit_training(model)"
      ],
      "metadata": {
        "id": "MhKNkBxPMQW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/kaggle/working/checkpoints\",\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=1,\n",
        "    save_strategy=\"epoch\",\n",
        "    save_steps=1,\n",
        "    logging_steps=10,\n",
        "    learning_rate=5e-5,\n",
        "    warmup_ratio=0.03,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=10\n",
        ")"
      ],
      "metadata": {
        "id": "a3iXjoZvMQUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize DPOTrainer\n",
        "trainer = DPOTrainer(\n",
        "    model=model,\n",
        "    peft_config=peft_config,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    args=training_args,\n",
        "    tokenizer=tokenizer,\n",
        "    beta=0.1\n",
        ")"
      ],
      "metadata": {
        "id": "_jjxoA6vMQR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Finish WandB run\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "J6HdwUG-MQPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save and push fine-tuned model to Hugging Face Hub\n",
        "fine_tuned_model_name = \"mistral_self_alignment_DPO\"\n",
        "trainer.model.save_pretrained(fine_tuned_model_name)\n",
        "commit_message = \"Initial adapter with DPO on sample dataset and 1 epoch\"\n",
        "trainer.model.push_to_hub(fine_tuned_model_name, commit_message=commit_message, use_temp_dir=False)\n",
        "tokenizer.push_to_hub(fine_tuned_model_name, commit_message=commit_message, use_temp_dir=False)"
      ],
      "metadata": {
        "id": "_UmQhGZOMWry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OnzrmRrnMWpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ibxFRByuMWnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nruI2h27MWkl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}